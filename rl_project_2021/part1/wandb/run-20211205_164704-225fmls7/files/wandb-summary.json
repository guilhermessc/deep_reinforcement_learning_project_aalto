{"ppo_eval/": {"timesteps": 897000, "returns": -345.48529052734375}, "_runtime": 6976, "_timestamp": 1638722600, "_step": 1334, "ppo_train/": {"step": 0, "lr": 0.0003, "val_loss": 0.01718319021165371, "pi_loss": -0.12138188630342484, "entropy": 1.9668684005737305, "approx_kl": 0.006051294039934874}}