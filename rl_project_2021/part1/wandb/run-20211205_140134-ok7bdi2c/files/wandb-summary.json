{"ppo_eval/": {"timesteps": 157000, "returns": -402.7488098144531}, "_runtime": 493, "_timestamp": 1638706187, "_step": 233, "ppo_train/": {"step": 0, "lr": 0.0003, "val_loss": 0.035831477493047714, "pi_loss": -0.14372950792312622, "entropy": 6.480942726135254, "approx_kl": 0.011705074459314346}}